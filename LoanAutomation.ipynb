{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "LPItkmheZZ1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa2ad0c4-3e49-4e7d-bed2-731ab3c3f5c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabula-py in /usr/local/lib/python3.10/dist-packages (2.8.2)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.23.5)\n",
            "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from tabula-py) (1.7.0)\n",
            "Requirement already satisfied: jpype1 in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2023.3.post1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from jpype1->tabula-py) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.25.3->tabula-py) (1.16.0)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-575467874526>:128: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  x = np.array(data.drop([predict], 1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client  11123  should be given the loan\n",
            "Model accuracy:  0.55\n"
          ]
        }
      ],
      "source": [
        "#Install tabula-py package\n",
        "!pip install tabula-py\n",
        "#Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import linear_model\n",
        "import sklearn\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import tabula as tabula\n",
        "\n",
        "# @title Please fill in the loan aplication entries\n",
        "Loan_ID = 11123 # @param {type:\"integer\"}\n",
        "Gender = 2 # @param [\"1\", \"2\"] {type:\"raw\"}\n",
        "Married = 1 # @param [\"0\", \"1\"] {type:\"raw\"}\n",
        "Dependents = 3 # @param {type:\"integer\"}\n",
        "Graduate = 1 # @param [\"0\", \"1\"] {type:\"raw\"}\n",
        "Self_Employed = 1 # @param [\"0\", \"1\"] {type:\"raw\"}\n",
        "ApplicantIncome = 3000 # @param {type:\"number\"}\n",
        "CoapplicantIncome = 1600 # @param {type:\"number\"}\n",
        "LoanAmount = 100 # @param {type:\"number\"}\n",
        "Loan_Amount_Term = 300 # @param {type:\"number\"}\n",
        "Credit_History = 1 # @param [\"0\", \"1\"] {type:\"raw\"}\n",
        "Property_Area = 2 # @param [\"1\", \"2\", \"3\"] {type:\"raw\"}\n",
        "\n",
        "#Parameters for the loan testing model\n",
        "Model_Test_Size = 0.1 # @param {type:\"number\"}\n",
        "Model_Iterations = 10000 # @param {type:\"number\"}\n",
        "\n",
        "#Create an array to save potential loan client data\n",
        "clientData = np.array([Gender, Married, Dependents, Graduate, Self_Employed, ApplicantIncome, CoapplicantIncome, LoanAmount, Loan_Amount_Term, Credit_History, Property_Area])\n",
        "clientData = clientData.reshape(1,11)\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Change the current working directory to the directory containing the file you want to open\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks')\n",
        "\n",
        "# Read the Zappy Loan Data.xlsx file\n",
        "data1 = pd.read_excel('Zappy Loan Data.xlsx')\n",
        "\n",
        "# Read the Loans_Database_Table.pdf file into a list of pandas DataFrames\n",
        "tables = tabula.read_pdf(\"Loans_Database_Table.pdf\", pages = 'all')\n",
        "\n",
        "\"\"\"Check whether a appendedDataFrames.csv file exsists and\n",
        "add an index to an already existing one to create a\n",
        "new one, where we will append all the pdf dataframes\n",
        "from the tables \"\"\"\n",
        "\n",
        "def create_unique_file(filename):\n",
        "    base_name, file_extension = os.path.splitext(filename)\n",
        "    index = 1\n",
        "\n",
        "    while True:\n",
        "        new_filename = f\"{base_name}_{index}{file_extension}\"\n",
        "\n",
        "        if not os.path.exists(new_filename):\n",
        "            with open(new_filename, 'w') as file:\n",
        "                pass\n",
        "            return new_filename\n",
        "\n",
        "        index += 1\n",
        "\n",
        "filename = \"appendedPdfDataFrames.csv\"\n",
        "new_file = create_unique_file(filename)\n",
        "\n",
        "# Append all the dataframes from all the tables to a csv file called appendedPdfDataFrames.csv\n",
        "def append_dataframes_to_csv(df_list, filename, mode='a'):\n",
        "\n",
        "    column_names = [\"Loan_ID\",\"Gender\", \"Married\", \"Dependents\",\"Graduate\", \"Self_Employed\",\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\",\"Loan_Amount_Term\",\"Credit_History\",\"Property_Area\",\"Loan_Status\"]\n",
        "\n",
        "    with open(filename, mode) as f:\n",
        "        if mode == 'w':\n",
        "            f.write(','.join(column_names) + '\\n')\n",
        "        for df in df_list:\n",
        "            df.to_csv(f, header=False, index=False)\n",
        "\n",
        "\n",
        "append_dataframes_to_csv([tables[0],tables[1],tables[2],tables[3],tables[4]\n",
        "                          ,tables[5],tables[6],tables[7],tables[8],tables[9]\n",
        "                          ,tables[10],tables[11],tables[12],tables[13]], new_file, mode='a')\n",
        "\n",
        "#Add column names\n",
        "def add_column_names_to_csv(filename, column_names):\n",
        "    with open(filename, 'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(','.join(column_names) + '\\n')\n",
        "        for line in data:\n",
        "            f.write(line)\n",
        "\n",
        "\n",
        "\n",
        "column_names = [\"Loan_ID\",\"Gender\", \"Married\", \"Dependents\",\"Graduate\", \"Self_Employed\",\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\",\"Loan_Amount_Term\",\"Credit_History\",\"Property_Area\",\"Loan_Status\"]\n",
        "\n",
        "\n",
        "add_column_names_to_csv(new_file, column_names)\n",
        "# Read the appendedPdfDataFrames.csv file and store the data in data2 variable\n",
        "data2 = pd.read_csv(new_file)\n",
        "\n",
        "# Combine the excel and pdf dataframes vertically into one dataframe\n",
        "data = pd.concat([data1, data2], axis=0)\n",
        "\n",
        "# Check if the 'Loan_Status_id' column exists\n",
        "if 'Loan_Status_id' not in data.columns:\n",
        "    \"\"\" Create the 'Loan_Status_id' column which has a 1 if the 'Loan_Status'\n",
        "    column has a 'Y' and a 0 if the 'Loan_Status' column has an 'N' \"\"\"\n",
        "\n",
        "    data['Loan_Status_id'] = data['Loan_Status'].map({'Y': 1, 'N': 0})\n",
        "\n",
        "# Create a variable  called 'predict' and assign the 'Loan_Status_id' to it.\n",
        "# This is because we want to test and predict it\n",
        "predict = \"Loan_Status_id\"\n",
        "\n",
        "# Select all the data we need for the model\n",
        "data = data[[\"Gender\", \"Married\", \"Dependents\",\"Graduate\", \"Self_Employed\",\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\",\"Loan_Amount_Term\",\"Credit_History\",\"Property_Area\",\"Loan_Status_id\"]]\n",
        "data = shuffle(data) # shuffle the data\n",
        "\n",
        "\"\"\" Create the x and y arrays where the x arrays will be the predictor\n",
        "variables and the y arrays the predicted variables \"\"\"\n",
        "x = np.array(data.drop([predict], 1))\n",
        "y =np.array(data[predict])\n",
        "\n",
        "\"\"\" Split the data into train and test propotions depending on the\n",
        "Model_Test_Size selected by the user \"\"\"\n",
        "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size=Model_Test_Size)\n",
        "\n",
        "\n",
        "\"\"\"Train the model by the number of times inputed by the user in the\n",
        "Model_Iterations entry and store the model with the best accuracy\n",
        "in the 'loanmodel.pickle' file \"\"\"\n",
        "best = 0\n",
        "for _ in range(Model_Iterations):\n",
        "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size=Model_Test_Size)\n",
        "\n",
        "    linear = linear_model.LinearRegression()\n",
        "\n",
        "    linear.fit(x_train, y_train)\n",
        "    acc = linear.score(x_test, y_test)\n",
        "\n",
        "    if acc > best:\n",
        "        best = acc\n",
        "        with open(\"loanmodel.pickle\", \"wb\") as f:\n",
        "            pickle.dump(linear, f)\n",
        "\n",
        "\"\"\"Load the model and use it to predict the \"Loan_Status_id\" of the\n",
        "potential loan client whose information has been entered in the form\"\"\"\n",
        "pickle_in = open(\"loanmodel.pickle\", \"rb\")\n",
        "linear = pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "predicted= linear.predict(clientData)\n",
        "\n",
        "\"\"\"Round off the predicted value to the nearest integer so that we can\n",
        "know whether the predicted value is a '0' for 'N' or a '1' for 'Y' \"\"\"\n",
        "predictedinteger = round(predicted[0])\n",
        "\n",
        "# Round off the model accuracy to two decimal places\n",
        "ModelAccuracy = round(best,2)\n",
        "\n",
        "\"\"\" If the predicted value is a '1' print out that the potential loan\n",
        "client can be given the loan, else print out they cannot be given\n",
        "the loan. The model accuracy should also be printed\"\"\"\n",
        "\n",
        "if predictedinteger == 1:\n",
        "  print(\"Client \", Loan_ID, \" should be given the loan\")\n",
        "  print(\"Model accuracy: \", ModelAccuracy)\n",
        "else:\n",
        "  print(\"Client \", Loan_ID, \" should not be given the loan\")\n",
        "  print(\"Model accuracy: \", ModelAccuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight I got from running the machine learning model is that it becomes more accurate when you increase the Model_Iterations and when you reduce the Model_Test_Size. The model becomes more accurate when you train it on a larger data set than the one you use to test it."
      ],
      "metadata": {
        "id": "ylWjnLz44tD_"
      }
    }
  ]
}